dataset_root: /projects/kaggle/LEAP/data
logs_root: /projects/kaggle/LEAP/logs
test_filename: test.csv
ss_filename: sample_submission.csv

hydra_dir: ${logs_root}/${now:%Y-%m-%d}_${now:%H-%M-%S}

seed: 42

dataset:
  n_rows: all # must be divisible by 200_000 or all
  train_val_split: [0.9, 0.1]
  num_features: 20
  num_targets: 368

checkpoint_callback:
  _target_: src.callbacks.ModelCheckpoint
  min_delta: 0.0
  mode: max
  filepath: ${hydra_dir}

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 1e-3
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: max
  factor: 0.1
  patience: 10

model:
  _target_: src.models.transformerv2.Model
  in_chans: ${dataset.num_features}
  max_len: 60
  embed_dim: 192
  ffn_layer: swiglu
  depth: 12
  num_heads: 6
  mlp_ratio: 2.0
  qkv_bias: True
  ffn_bias: True
  proj_bias: True
  drop_path_rate: 0.0
  drop_path_uniform: False

criterion:
  _target_: src.utils.MaskedL1Loss
  _partial_: True

criterion_delta:
  _target_: src.utils.MaskedL1Loss
  _partial_: True

trainer:
  epochs: 50
  checkpoint_dir: ${hydra_dir}
  norm_value: 1.0
  batch_size: 256
  num_workers: 8

hydra:
  run:
    dir: ${hydra_dir}
  job:
    chdir: True
