dataset_root: /projects/kaggle/LEAP/data/
logs_root: /projects/kaggle/LEAP/logs/
train_filename: train.csv
test_filename: test.csv
ss_filename: sample_submission.csv

hydra_dir: ${logs_root}/${now:%Y-%m-%d}_${now:%H-%M-%S}

seed: 42

dataset:
  n_rows: 1_000_000
  train_val_split: [0.8, 0.2]
  batch_size: 256
  num_workers: 10
  num_features: 19
  num_targets: 368

early_stopping:
  _target_: src.utils.EarlyStopping
  patience: 10
  delta: 0.0
  verbose: True
  on_each_epoch: False

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 1e-3
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: max
  factor: 0.1
  patience: 10

model:
  _target_: src.models.transformerv2.Model
  in_chans: 19
  max_len: 60
  embed_dim: 192
  embed_layer: fc
  head: mlp
  ffn_layer: swiglu
  depth: 12
  num_heads: 4
  mlp_ratio: 2.0
  qkv_bias: True
  ffn_bias: True
  proj_bias: True
  drop_path_rate: 0.0
  drop_path_uniform: False

trainer:
  epochs: 60
  checkpoint_dir: ${hydra_dir}
  norm_value: 1.0

hydra:
  run:
    dir: ${hydra_dir}
  job:
    chdir: True
